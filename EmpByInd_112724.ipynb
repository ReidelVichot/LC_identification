{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReidelVichot/LC_identification/blob/main/EmpByInd_112724.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. PROBLEM DEFINITION"
      ],
      "metadata": {
        "id": "Rqdn9j66FRnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Background**\n",
        "\n",
        "“A logistics cluster (LC) is defined as the geographical concentration of firms providing logistics services, such as transportation carriers, warehousing providers, third-party logistics (3PL-s), and forwarders, as well as some other enterprises that are mainly in the logistics business, including logistics enterprises to provide services to various industries” (Rivera et al., 2014, p. 223).  \n",
        "\n",
        "Several relevant scholars in the field of logistics claim that clustering logistic activity has a positive impact on the efficiency of the economic activity, reduction of costs, and increase of collaboration among the firms that belong to the cluster (Rivera et al., 2014; Rivera, Gligor, et al., 2016; Rivera, Sheffi, et al., 2016; Sheffi, 2013, 2012). Although some of these authors mention that some of these benefits require some trade-offs (Rivera, Gligor, et al., 2016), these trade-offs are not further explored, resulting in an incomplete understanding of the socio-economic effects of the agglomeration of logistics activity. This becomes more problematic given that governments around the world seem to be embracing the idea of logistics clusters being some sort of panacea for economic development based on supply chain management improvements (Baranowski et al., 2015; Baydar et al., 2019; Chung, 2016), even though empirical studies that assess the role of government spending on the formation of logistics clusters are lacking (Liu et al., 2022). In other words, the field still lacks methodological and theoretical development, resulting in an incomplete understanding of the mechanisms of logistical clustering and their socio-economic effects.\n",
        "\n",
        "**Problem**\n",
        "\n",
        "There is not a current database of logistics clusters in the US. However, Rivera et al (2014) designed a method to test logistical agglomeration in US counties using NAICS codes and [CBP](https://www.census.gov/programs-surveys/cbp.html) information. Before conducting analyis on the effects of Logistics Clusters on society and the role of governments in their formation it is necessary to have an accurate picture of all logistics clusters in the US. For this purpose, I will extend Reviera's et al (2014) methodology to all the CBP years in which NAICS codes are used and use this database for future analyses."
      ],
      "metadata": {
        "id": "LvmLdFxsFRTo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. DATA COLLECTION"
      ],
      "metadata": {
        "id": "AIyjkt-fFTKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RylmOoWgr-bA",
        "outputId": "fe830667-ae81-48be-aa53-d526aa478809"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "import time\n",
        "\n",
        "# -- this line is to make pandas future-proof, Copy-on-Write will become the default in pandas 3.0.\n",
        "pd.options.mode.copy_on_write = True\n",
        "\n",
        "pd.set_option(\"future.no_silent_downcasting\", True)\n",
        "\n",
        "# -- Set the data path\n",
        "dpath = \"/content/drive/MyDrive/Disertation/\""
      ],
      "metadata": {
        "id": "TYXSF8rbsAos"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "for year in range(1998, 2022):\n",
        "  xx = str(year)[2:]\n",
        "  fname = dpath + \"CBP_data/cbp\" + xx + \"co/cbp\" + xx + \"co.txt\"\n",
        "  temp = pd.read_csv(fname)\n",
        "  if year == 2015:\n",
        "    temp.columns = temp.columns.str.lower()\n",
        "  # -- add a year column\n",
        "  temp[\"year\"] = year\n",
        "  # -- add a GEOID\n",
        "  temp[\"GEOID\"] = temp.fipstate.astype(str).str.zfill(2) + temp.fipscty.astype(str).str.zfill(3)\n",
        "  # -- create a global variable and save a dataframe into it\n",
        "  # -- temp1 contains the 2-digits naics codes\n",
        "  temp1 = temp[temp[\"naics\"].str.endswith(\"----\")]\n",
        "  temp1 = temp1[~temp1[\"naics\"].str.startswith(\"--\")]\n",
        "  temp1[\"naics\"] = temp1[\"naics\"].str[:2]\n",
        "  # -- get the unique 2-digits naics codes\n",
        "  digits = tuple(temp1[\"naics\"].unique())\n",
        "\n",
        "  # -- get 3-digit naics that do not include the 2-digit ones.\n",
        "  temp2 =temp[temp['naics'].str.endswith('///')]\n",
        "  temp2 = temp2[~temp2['naics'].str.startswith(digits)]\n",
        "  temp2['naics'] = temp2['naics'].str[:2]\n",
        "\n",
        "\n",
        "  globals()[\"ind\" + xx] = pd.concat([temp1, temp2])\n",
        "  # -- delete to save RAM\n",
        "  del temp\n",
        "  del temp1\n",
        "  del temp2\n",
        "t1 = time.time()\n",
        "print(\"Execution Time: \", (t1 - t0)/60, \" mins\")"
      ],
      "metadata": {
        "id": "Z3YszK3HbaOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "207dab2d-4512-4394-a35e-2513eb14496b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time:  4.22069065173467  mins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. DATA PREPARATION"
      ],
      "metadata": {
        "id": "bbhRsKK6FTrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The CBP record layouts are different accross years.\n",
        "cols_98_16 = ['fipstate', 'fipscty', 'naics', 'empflag', 'emp', 'ap', 'est',\n",
        "              'n1_4', 'n5_9', 'n10_19', 'n20_49', 'n50_99', 'n100_249', 'n250_499',\n",
        "              'n500_999','n1000', 'n1000_1', 'n1000_2', 'n1000_3', 'n1000_4',\n",
        "              'year', 'GEOID']\n",
        "\n",
        "cols_17    = ['fipstate', 'fipscty', 'naics', 'empflag', 'emp', 'ap', 'est',\n",
        "              'n<5', 'n5_9', 'n10_19', 'n20_49', 'n50_99', 'n100_249', 'n250_499',\n",
        "              'n500_999','n1000', 'n1000_1', 'n1000_2', 'n1000_3', 'n1000_4',\n",
        "              'year', 'GEOID']\n",
        "\n",
        "cols_18_21 = ['fipstate', 'fipscty', 'naics', 'emp_nf',  'emp', 'ap', 'est',\n",
        "              'n<5', 'n5_9', 'n10_19', 'n20_49', 'n50_99', 'n100_249', 'n250_499',\n",
        "              'n500_999','n1000', 'n1000_1', 'n1000_2', 'n1000_3', 'n1000_4',\n",
        "              'year', 'GEOID']\n",
        "\n",
        "t0 = time.time()\n",
        "for year in range(1998, 2017):\n",
        "  xx = str(year)[2:]\n",
        "  globals()[\"ind\" + xx] = globals()[\"ind\" + xx][cols_98_16]\n",
        "\n",
        "ind17 = ind17[cols_17]\n",
        "ind17.columns = ind98.columns\n",
        "\n",
        "#####  NOTE: CBP17 has object-type columns for the employment by establishment size.\n",
        "# from 2017-2021 there are values that have N instead of 0 for emp by est size\n",
        "ind17[ind17.columns[7:19]] = ind17[ind17.columns[7:19]].replace(\"N\", 0).astype(int)\n",
        "\n",
        "for year in range(2018, 2022):\n",
        "  xx = str(year)[2:]\n",
        "  globals()[\"ind\" + xx] = globals()[\"ind\" + xx][cols_18_21]\n",
        "  globals()[\"ind\" + xx][globals()[\"ind\" + xx].columns[7:19]] = globals()[\"ind\" + xx][globals()[\"ind\" + xx].columns[7:19]].replace(\"N\", 0).astype(int)\n",
        "  globals()[\"ind\" + xx].columns = ind98.columns\n",
        "\n",
        "# -- Between 1998 and 2017, there was a suppression flag (empflag) that affects\n",
        "#    the employment. Instead of using employment as it is, I will adjust it\n",
        "#    based on the middle point of the employment by establishment size.\n",
        "\n",
        "# -- create an unified dataframe for all years (1998-2017)\n",
        "frames = [ind98, ind99, ind00, ind01, ind02, ind03, ind04, ind05, ind06, ind07,\n",
        "          ind08, ind09, ind10, ind11, ind12, ind13, ind14, ind15, ind16, ind17,\n",
        "          ind18, ind19, ind20, ind21]\n",
        "\n",
        "ind = pd.concat(frames).reset_index().drop(columns=\"index\")\n",
        "# -- lambda funditon to estimate employment if the employment is flagged\n",
        "t0 = time.time()\n",
        "ind['emp_adj'] = ind.apply(lambda row: row[\"emp\"]\n",
        "                           if pd.isna(row['empflag'])\n",
        "                           else row['n1_4']*2.5 + row['n5_9']*7 +\n",
        "                                row['n10_19']*14.5 + row['n20_49']*34.5 +\n",
        "                                row['n50_99']*74.5 + row['n100_249']*174.5 +\n",
        "                                row['n250_499']*374.5 + row['n500_999']*749.5 +\n",
        "                                row['n1000']*1000 , axis=1)\n",
        "ind = ind.drop(columns=['n1_4', 'n5_9', 'n10_19', 'n20_49', 'n50_99',\n",
        "                        'n100_249', 'n250_499', 'n500_999', 'n1000',\n",
        "                        'n1000_1', 'n1000_2', 'n1000_3', 'n1000_4'])\n",
        "ind[\"emp_adj\"] = ind.apply(lambda row: row[\"emp\"] if (row[\"year\"]==2018)|(row[\"year\"]==2019)|(row[\"year\"]==2020)|(row[\"year\"]==2021) else row[\"emp_adj\"], axis=1)\n",
        "\n",
        "# this cbp is from 1998-2021\n",
        "ind = ind.groupby([\"GEOID\", \"year\", \"fipstate\", \"fipscty\", \"naics\"]).sum(numeric_only=True).reset_index()\n",
        "\n",
        "# -- save the cvs to use it later\n",
        "ind.to_csv(dpath + \"industries.csv\", index = False)\n",
        "\n",
        "t1 = time.time()\n",
        "print(\"Execution Time: \", (t1-t0)/60, \" mins\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "tngQkfbFrpfr",
        "outputId": "508d84a7-c1f2-4b5a-bf13-46f8ac39fc84"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ff65f0025bac>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# -- save the cvs to use it later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"industries.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 )\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3965\u001b[0m         )\n\u001b[1;32m   3966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3967\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3968\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         )\n\u001b[0;32m-> 1014\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m             )\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_need_to_save_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstart_i\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslicer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_number_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         libwriters.write_csv_rows(\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mwriters.pyx\u001b[0m in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind00.naics.unique()"
      ],
      "metadata": {
        "id": "l5KygjpHy5cI",
        "outputId": "153a2f9d-816f-48eb-c8ce-f9232a62f686",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['11----', '21----', '22----', '23----', '31----', '42----',\n",
              "       '44----', '48----', '51----', '52----', '53----', '54----',\n",
              "       '55----', '56----', '61----', '62----', '71----', '72----',\n",
              "       '81----', '99----', '95----'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this line to get access to the most current version of the CBP\n",
        "ind_temp = pd.read_csv(dpath + \"industries.csv\")\n",
        "ind_temp[\"GEOID\"] = ind_temp[\"GEOID\"].astype(str).apply(lambda x: x.zfill(5))\n",
        "ind = ind_temp\n",
        "del ind_temp"
      ],
      "metadata": {
        "id": "f0JlxdnopzTB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "replace cat_ind=1 if ind1990>=10 & ind1990<=60 //Agriculture, forestry, fisheries, mining, and construction\n",
        "replace cat_ind=2 if ind1990>=100 & ind1990<=392 //Manufacturing\n",
        "replace cat_ind=3 if ind1990>=400 & ind1990<=691 //Transportation, communications, utilities, wholesale, and retail trade\n",
        "replace cat_ind=4 if ind1990>=700 & ind1990<=791 //Finance, insurance, real estate, and business, repair, and personal services\n",
        "replace cat_ind=5 if ind1990>=800 & ind1990<=960 //Entertainment and recreation, professional and related services, public administration, and active duty military\n"
      ],
      "metadata": {
        "id": "bv0mpA0zupVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --Removing non-contiguous US counties\n",
        "# Alaska, Hawaii, American Samoa, Guam, Nothern Marianas, Puerto Rico,\n",
        "# Virgin Islands\n",
        "nc_states = [2, 15, 60, 66, 69, 72, 78]\n",
        "for i in nc_states:\n",
        "  print(\"IND      \", len(ind))\n",
        "  ind = ind[ind[\"fipstate\"] != i]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ge08F5ZlFYW",
        "outputId": "ca70e792-d64a-45bc-fc99-57b0889061a0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IND       1376899\n",
            "IND       1365570\n",
            "IND       1363486\n",
            "IND       1363486\n",
            "IND       1363486\n",
            "IND       1363486\n",
            "IND       1363486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind['naics'] = ind['naics'].str[:2].astype(int)"
      ],
      "metadata": {
        "id": "jq618WldwVYd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind['naics'].unique()"
      ],
      "metadata": {
        "id": "2-3z5FYNxIqk",
        "outputId": "b6fd9585-07c8-490a-cbf8-1e73855d72ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['11', '21', '22', '23', '31', '42', '44', '48', '51', '52', '53',\n",
              "       '54', '55', '56', '61', '62', '71', '72', '81', '99', '95'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to categorize industries based on NAICS codes\n",
        "def categorize_industry(naics_code):\n",
        "    if naics_code in [11, 21, 23]:  # Agriculture, Forestry, Fishing, Mining, Construction\n",
        "        return 1\n",
        "    elif 31 <= naics_code <= 33:  # Manufacturing\n",
        "        return 2\n",
        "    elif naics_code in [42, 44, 45, 48, 49, 22, 51]:  # Transportation, Communications, Utilities, Wholesale, Retail\n",
        "        return 3\n",
        "    elif naics_code in [52, 53, 54, 56, 81]:  # Finance, Insurance, Real Estate, Business Services\n",
        "        return 4\n",
        "    elif naics_code in [51, 61, 62, 71, 72, 81, 92]:  # Other Services, Public Administration\n",
        "        return 5\n",
        "    else:\n",
        "        return None  # Handle cases with invalid or uncategorized NAICS codes\n",
        "\n",
        "# Apply the function to create the 'cat_ind' variable\n",
        "df['cat_ind'] = df['naics'].apply(categorize_industry)\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "vPolZfSDw8cE",
        "outputId": "4055fff6-ccfa-4ee8-ca25-da8298a04ca4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-13544ff8b0ad>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Apply the function to create the 'cat_ind' variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cat_ind'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'naics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorize_industry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. MACHINE LEARNING"
      ],
      "metadata": {
        "id": "lcLQnk75FUC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. PROBLEM SOLUTION"
      ],
      "metadata": {
        "id": "PHET5dqCFUUi"
      }
    }
  ]
}