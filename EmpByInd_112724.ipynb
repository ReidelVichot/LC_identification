{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReidelVichot/LC_identification/blob/main/EmpByInd_112724.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. PROBLEM DEFINITION"
      ],
      "metadata": {
        "id": "Rqdn9j66FRnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Background**\n",
        "\n",
        "“A logistics cluster (LC) is defined as the geographical concentration of firms providing logistics services, such as transportation carriers, warehousing providers, third-party logistics (3PL-s), and forwarders, as well as some other enterprises that are mainly in the logistics business, including logistics enterprises to provide services to various industries” (Rivera et al., 2014, p. 223).  \n",
        "\n",
        "Several relevant scholars in the field of logistics claim that clustering logistic activity has a positive impact on the efficiency of the economic activity, reduction of costs, and increase of collaboration among the firms that belong to the cluster (Rivera et al., 2014; Rivera, Gligor, et al., 2016; Rivera, Sheffi, et al., 2016; Sheffi, 2013, 2012). Although some of these authors mention that some of these benefits require some trade-offs (Rivera, Gligor, et al., 2016), these trade-offs are not further explored, resulting in an incomplete understanding of the socio-economic effects of the agglomeration of logistics activity. This becomes more problematic given that governments around the world seem to be embracing the idea of logistics clusters being some sort of panacea for economic development based on supply chain management improvements (Baranowski et al., 2015; Baydar et al., 2019; Chung, 2016), even though empirical studies that assess the role of government spending on the formation of logistics clusters are lacking (Liu et al., 2022). In other words, the field still lacks methodological and theoretical development, resulting in an incomplete understanding of the mechanisms of logistical clustering and their socio-economic effects.\n",
        "\n",
        "**Problem**\n",
        "\n",
        "There is not a current database of logistics clusters in the US. However, Rivera et al (2014) designed a method to test logistical agglomeration in US counties using NAICS codes and [CBP](https://www.census.gov/programs-surveys/cbp.html) information. Before conducting analyis on the effects of Logistics Clusters on society and the role of governments in their formation it is necessary to have an accurate picture of all logistics clusters in the US. For this purpose, I will extend Reviera's et al (2014) methodology to all the CBP years in which NAICS codes are used and use this database for future analyses."
      ],
      "metadata": {
        "id": "LvmLdFxsFRTo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. DATA COLLECTION"
      ],
      "metadata": {
        "id": "AIyjkt-fFTKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RylmOoWgr-bA",
        "outputId": "e1f7eb00-41c9-47c0-9c79-d09da916655c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "import time\n",
        "\n",
        "# -- this line is to make pandas future-proof, Copy-on-Write will become the default in pandas 3.0.\n",
        "pd.options.mode.copy_on_write = True\n",
        "\n",
        "pd.set_option(\"future.no_silent_downcasting\", True)\n",
        "\n",
        "# -- Set the data path\n",
        "dpath = \"/content/drive/MyDrive/Disertation/\""
      ],
      "metadata": {
        "id": "TYXSF8rbsAos"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "for year in range(1998, 2022):\n",
        "  xx = str(year)[2:]\n",
        "  fname = dpath + \"CBP_data/cbp\" + xx + \"co/cbp\" + xx + \"co.txt\"\n",
        "  temp = pd.read_csv(fname)\n",
        "  if year == 2015:\n",
        "    temp.columns = temp.columns.str.lower()\n",
        "  # -- add a year column\n",
        "  temp[\"year\"] = year\n",
        "  # -- add a GEOID\n",
        "  temp[\"GEOID\"] = temp.fipstate.astype(str).str.zfill(2) + temp.fipscty.astype(str).str.zfill(3)\n",
        "  # -- create a global variable and save a dataframe into it\n",
        "  # -- temp1 contains the 2-digits naics codes\n",
        "  temp1 = temp[temp[\"naics\"].str.endswith(\"----\")]\n",
        "  temp1 = temp1[~temp1[\"naics\"].str.startswith(\"--\")]\n",
        "  temp1[\"naics\"] = temp1[\"naics\"].str[:2]\n",
        "  # -- get the unique 2-digits naics codes\n",
        "  digits = tuple(temp1[\"naics\"].unique())\n",
        "\n",
        "  # -- get 3-digit naics that do not include the 2-digit ones.\n",
        "  temp2 =temp[temp['naics'].str.endswith('///')]\n",
        "  temp2 = temp2[~temp2['naics'].str.startswith(digits)]\n",
        "  temp2['naics'] = temp2['naics'].str[:2]\n",
        "\n",
        "\n",
        "  globals()[\"ind\" + xx] = pd.concat([temp1, temp2])\n",
        "  # -- delete to save RAM\n",
        "  del temp\n",
        "  del temp1\n",
        "  del temp2\n",
        "t1 = time.time()\n",
        "print(\"Execution Time: \", (t1 - t0)/60, \" mins\")"
      ],
      "metadata": {
        "id": "Z3YszK3HbaOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4162729-377d-4730-9fa9-d6e5a8d9e776"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time:  3.5365217367808026  mins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. DATA PREPARATION"
      ],
      "metadata": {
        "id": "bbhRsKK6FTrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The CBP record layouts are different accross years.\n",
        "cols_98_16 = ['fipstate', 'fipscty', 'naics', 'empflag', 'emp', 'ap', 'est',\n",
        "              'n1_4', 'n5_9', 'n10_19', 'n20_49', 'n50_99', 'n100_249', 'n250_499',\n",
        "              'n500_999','n1000', 'n1000_1', 'n1000_2', 'n1000_3', 'n1000_4',\n",
        "              'year', 'GEOID']\n",
        "\n",
        "cols_17    = ['fipstate', 'fipscty', 'naics', 'empflag', 'emp', 'ap', 'est',\n",
        "              'n<5', 'n5_9', 'n10_19', 'n20_49', 'n50_99', 'n100_249', 'n250_499',\n",
        "              'n500_999','n1000', 'n1000_1', 'n1000_2', 'n1000_3', 'n1000_4',\n",
        "              'year', 'GEOID']\n",
        "\n",
        "cols_18_21 = ['fipstate', 'fipscty', 'naics', 'emp_nf',  'emp', 'ap', 'est',\n",
        "              'n<5', 'n5_9', 'n10_19', 'n20_49', 'n50_99', 'n100_249', 'n250_499',\n",
        "              'n500_999','n1000', 'n1000_1', 'n1000_2', 'n1000_3', 'n1000_4',\n",
        "              'year', 'GEOID']\n",
        "\n",
        "t0 = time.time()\n",
        "for year in range(1998, 2017):\n",
        "  xx = str(year)[2:]\n",
        "  globals()[\"ind\" + xx] = globals()[\"ind\" + xx][cols_98_16]\n",
        "\n",
        "ind17 = ind17[cols_17]\n",
        "ind17.columns = ind98.columns\n",
        "\n",
        "#####  NOTE: CBP17 has object-type columns for the employment by establishment size.\n",
        "# from 2017-2021 there are values that have N instead of 0 for emp by est size\n",
        "ind17[ind17.columns[7:19]] = ind17[ind17.columns[7:19]].replace(\"N\", 0).astype(int)\n",
        "\n",
        "for year in range(2018, 2022):\n",
        "  xx = str(year)[2:]\n",
        "  globals()[\"ind\" + xx] = globals()[\"ind\" + xx][cols_18_21]\n",
        "  globals()[\"ind\" + xx][globals()[\"ind\" + xx].columns[7:19]] = globals()[\"ind\" + xx][globals()[\"ind\" + xx].columns[7:19]].replace(\"N\", 0).astype(int)\n",
        "  globals()[\"ind\" + xx].columns = ind98.columns\n",
        "\n",
        "# -- Between 1998 and 2017, there was a suppression flag (empflag) that affects\n",
        "#    the employment. Instead of using employment as it is, I will adjust it\n",
        "#    based on the middle point of the employment by establishment size.\n",
        "\n",
        "# -- create an unified dataframe for all years (1998-2017)\n",
        "frames = [ind98, ind99, ind00, ind01, ind02, ind03, ind04, ind05, ind06, ind07,\n",
        "          ind08, ind09, ind10, ind11, ind12, ind13, ind14, ind15, ind16, ind17,\n",
        "          ind18, ind19, ind20, ind21]\n",
        "\n",
        "ind = pd.concat(frames).reset_index().drop(columns=\"index\")\n",
        "# -- lambda funditon to estimate employment if the employment is flagged\n",
        "t0 = time.time()\n",
        "ind['emp_adj'] = ind.apply(lambda row: row[\"emp\"]\n",
        "                           if pd.isna(row['empflag'])\n",
        "                           else row['n1_4']*2.5 + row['n5_9']*7 +\n",
        "                                row['n10_19']*14.5 + row['n20_49']*34.5 +\n",
        "                                row['n50_99']*74.5 + row['n100_249']*174.5 +\n",
        "                                row['n250_499']*374.5 + row['n500_999']*749.5 +\n",
        "                                row['n1000']*1000 , axis=1)\n",
        "ind = ind.drop(columns=['n1_4', 'n5_9', 'n10_19', 'n20_49', 'n50_99',\n",
        "                        'n100_249', 'n250_499', 'n500_999', 'n1000',\n",
        "                        'n1000_1', 'n1000_2', 'n1000_3', 'n1000_4'])\n",
        "ind[\"emp_adj\"] = ind.apply(lambda row: row[\"emp\"] if (row[\"year\"]==2018)|(row[\"year\"]==2019)|(row[\"year\"]==2020)|(row[\"year\"]==2021) else row[\"emp_adj\"], axis=1)\n",
        "\n",
        "# this cbp is from 1998-2021\n",
        "ind = ind.groupby([\"GEOID\", \"year\", \"fipstate\", \"fipscty\", \"naics\"]).sum(numeric_only=True).reset_index()\n",
        "\n",
        "# -- save the cvs to use it later\n",
        "ind.to_csv(dpath + \"industries.csv\", index = False)\n",
        "\n",
        "t1 = time.time()\n",
        "print(\"Execution Time: \", (t1-t0)/60, \" mins\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tngQkfbFrpfr",
        "outputId": "27bfa742-fa9f-447b-c8a9-fb0ac447ff96"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time:  1.7532111048698424  mins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this line to get access to the most current version of the industries\n",
        "ind_temp = pd.read_csv(dpath + \"industries.csv\")\n",
        "ind_temp[\"GEOID\"] = ind_temp[\"GEOID\"].astype(str).apply(lambda x: x.zfill(5))\n",
        "ind = ind_temp\n",
        "del ind_temp"
      ],
      "metadata": {
        "id": "f0JlxdnopzTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --Removing non-contiguous US counties\n",
        "# Alaska, Hawaii, American Samoa, Guam, Nothern Marianas, Puerto Rico,\n",
        "# Virgin Islands\n",
        "nc_states = [2, 15, 60, 66, 69, 72, 78]\n",
        "for i in nc_states:\n",
        "  print(\"IND      \", len(ind))\n",
        "  ind = ind[ind[\"fipstate\"] != i]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ge08F5ZlFYW",
        "outputId": "2baa1eb4-298a-4be3-e1d7-1fac8aa5fa3f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IND       1624349\n",
            "IND       1611442\n",
            "IND       1608963\n",
            "IND       1608963\n",
            "IND       1608963\n",
            "IND       1608963\n",
            "IND       1608963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cat_ind=1 //Agriculture, forestry, fisheries, mining, and construction\n",
        "\n",
        "cat_ind=2  //Manufacturing\n",
        "\n",
        "cat_ind=3  //Transportation, communications, utilities, wholesale, and retail trade\n",
        "\n",
        "cat_ind=4  //Finance, insurance, real estate, and business, repair, and personal services\n",
        "\n",
        "cat_ind=5  //Entertainment and recreation, professional and related services, public administration, and active duty military\n"
      ],
      "metadata": {
        "id": "bv0mpA0zupVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ind['naics'] = ind['naics'].str[:2].astype(int)\n",
        "# Function to categorize industries based on NAICS codes\n",
        "def categorize_industry(naics_code):\n",
        "    if naics_code in [11, 21, 23]:  # Agriculture, Forestry, Fishing, Mining, Construction\n",
        "        return 1\n",
        "    elif 31 <= naics_code <= 33:  # Manufacturing\n",
        "        return 2\n",
        "    elif naics_code in [42, 44, 45, 48, 49, 22, 51]:  # Transportation, Communications, Utilities, Wholesale, Retail\n",
        "        return 3\n",
        "    elif naics_code in [52, 53, 54, 56, 81]:  # Finance, Insurance, Real Estate, Business Services\n",
        "        return 4\n",
        "    elif naics_code in [51, 61, 62, 71, 72, 81, 92]:  # Other Services, Public Administration\n",
        "        return 5\n",
        "    else:\n",
        "        return None  # Handle cases with invalid or uncategorized NAICS codes\n",
        "\n",
        "# Apply the function to create the 'cat_ind' variable\n",
        "ind['cat_ind'] = ind['naics'].apply(categorize_industry)"
      ],
      "metadata": {
        "id": "vPolZfSDw8cE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. MACHINE LEARNING"
      ],
      "metadata": {
        "id": "lcLQnk75FUC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. PROBLEM SOLUTION"
      ],
      "metadata": {
        "id": "PHET5dqCFUUi"
      }
    }
  ]
}